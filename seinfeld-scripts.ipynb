{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing necessary libraries\n",
    "import urllib.request as ur\n",
    "import pandas as pd\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#opening the seinfeld database and converting it into an object\n",
    "main = ur.urlopen(\"https://www.imsdb.com/TV/Seinfeld.html\")\n",
    "mainread = str(main.read())\n",
    "\n",
    "#defining a function to grab the urls from the webpage\n",
    "def titlegrab(webpage):\n",
    "    webobj = BeautifulSoup(webpage)\n",
    "    alllinks = webobj.find_all('a')\n",
    "    dirtylinks = alllinks[64:-7]\n",
    "    titles = []\n",
    "    for i in range(len(dirtylinks)):\n",
    "        squote = str(dirtylinks[i]).find(\"-\",0)+2\n",
    "        equote = str(dirtylinks[i]).find(\"Script\",squote)-1\n",
    "        titles = titles + [str(dirtylinks[i])[squote:equote]]\n",
    "    return titles\n",
    "\n",
    "titles = titlegrab(mainread)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining a function to convert a list of unmodified links into usable links\n",
    "def urlbuilder(list):\n",
    "        prelink = \"https://www.imsdb.com/transcripts/Seinfeld-\"\n",
    "        rawlinks = list\n",
    "        final_urls = []\n",
    "        for i in range(len(list)):\n",
    "            extension = '-'.join(rawlinks[i].split(\" \"))\n",
    "            final_urls = final_urls + [prelink + extension +\".html\"]\n",
    "        return final_urls\n",
    "        \n",
    "links = urlbuilder(titles)        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Removing html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def cleanup_script(link):\n",
    "    raw_script_page = ur.urlopen(link)\n",
    "    raw_script = str(raw_script_page.read())\n",
    "    raw_script = \"'\".join(raw_script.split(\"\\\\'\"))\n",
    "    raw_script2 = raw_script.split(\"<body>\")\n",
    "    the_end = raw_script2[1].find('THE END',0)\n",
    "    raw_script3 = raw_script2[1][:the_end+7]\n",
    "    soup_script = BeautifulSoup(raw_script3)\n",
    "    clean_script = soup_script.get_text()\n",
    "    clean_script = clean_script.split(\"\\\\n\")\n",
    "    return clean_script\n",
    "\n",
    "all_raw_script = []\n",
    "for i in range(len(titles)):\n",
    "    script = cleanup_script(links[i])\n",
    "    all_raw_script = all_raw_script + [script]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parsing the script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining a function to remove unwanted \"space\" elements, \n",
    "#stripping elements of unnecessary spaces, \n",
    "#and joining lines into one element.\n",
    "\n",
    "def parsing_lines(script):\n",
    "    \n",
    "    #Removing the space elements.\n",
    "    script_spaceless = []\n",
    "    for i in range(len(script)):\n",
    "        if script[i] != '' and script[i] != ' ' and script[i] != '               ':\n",
    "            script_spaceless = script_spaceless + [script[i]]\n",
    "    script_stripped = []\n",
    "    \n",
    "    #Stripping every element of the spaces that surround them.\n",
    "    for i in range(len(script_spaceless)):\n",
    "        script_stripped = script_stripped + [script_spaceless[i].strip(' ')]\n",
    "    \n",
    "    #Joining all the line elements corresponding to one line \n",
    "    #into one element.\n",
    "    final_script = []\n",
    "    tempstr = ''\n",
    "    for i in range(len(script_stripped)):\n",
    "        if bool(re.search('([a-z])',script_stripped[i]) or re.search('\\W+',script_stripped[i])) == False:  \n",
    "            if tempstr != '':\n",
    "                tempstr = tempstr.strip(' ')\n",
    "                final_script = final_script + [tempstr]\n",
    "            final_script = final_script + [script_stripped[i]]\n",
    "            tempstr = ''\n",
    "        else:\n",
    "            tempstr = tempstr + script_stripped[i] + ' '\n",
    "    return final_script\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_script = []\n",
    "for i in range(len(all_raw_script)):\n",
    "    all_script = all_script + [parsing_lines(all_raw_script[i])]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
